[{"speaker": 1, "text": "Okay. Alright well, good evening everybody.", "timestamp": 0.0, "labels": ["environment", "safety", "AI", "gender"], "scores": [0.5976117253303528, 0.5813780426979065, 0.19949279725551605, 0.11550228297710419]}, {"speaker": 1, "text": "Welcome Elon. Thanks for being here.", "timestamp": 0.0, "labels": ["environment", "safety", "AI", "gender"], "scores": [0.6044802665710449, 0.570954442024231, 0.3327483832836151, 0.04869142174720764]}, {"speaker": 1, "text": "Uh we feel we feel very privileged we're excited to have you. Right so, I'm gonna start with some questions and then we're gonna open it up.", "timestamp": 0.0, "labels": ["environment", "safety", "AI", "gender"], "scores": [0.7372773289680481, 0.6687701344490051, 0.38763347268104553, 0.21756500005722046]}, {"speaker": 1, "text": "Let me get straight into it. So Bill Gates said there is no one in our time who has done more to push the bounds of science innovation than you.", "timestamp": 0.0, "labels": ["AI", "safety", "environment", "gender"], "scores": [0.12079054862260818, 0.03230156749486923, 0.025431837886571884, 0.001226621214300394]}, {"speaker": 1, "text": "Yeah well, that's it. That's a nice thing to have s anyone say about you.", "timestamp": 0.0, "labels": ["environment", "safety", "AI", "gender"], "scores": [0.5097339749336243, 0.3487604260444641, 0.11829878389835358, 0.07429072260856628]}, {"speaker": 1, "text": "Nice coming from Bill Gates. But oddly enough, when it comes to A.I. actually for around a decade, you've almost been doing the opposite and saying hang on we need to think about what we're doing and what we're pushing here and what do we do to make this safe and and actually maybe we shouldn't be pushing as faster uh as hard as we are.", "timestamp": 0.0, "labels": ["AI", "safety", "environment", "gender"], "scores": [0.9927104115486145, 0.9856116771697998, 0.3911373019218445, 0.007928491570055485]}, {"speaker": 1, "text": "Like I mean you've been doing it for a decade. Like what was it that caused you to think about it that way and you know why do we need to be worried?", "timestamp": 0.0, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.39732396602630615, 0.3806735575199127, 0.08786863833665848, 0.07519275695085526]}, {"speaker": 2, "text": "With A.I. of it since I was immersed in um technology I have been immersed in technology for a long time I could see it coming. Um so uh but I think this year was uh that there've been a number of of breakthroughs.", "timestamp": 59.2, "labels": ["AI", "safety", "environment", "gender"], "scores": [0.9884392619132996, 0.4694660007953644, 0.4051598310470581, 0.01692700758576393]}, {"speaker": 2, "text": "I mean w you know the point at which someone can see a dynamically created video of themselves um you know like it sorta could make a video of you saying anything in real time um or me um and uh so that sort of the the deep pick video is which are really incredibly good in sometimes more convincing than real ones um and a bit deep real um and um and then and then obviously th things like charge E.V.T. were were quite remarkable. Now I saw uh G.P.T. one G.P. two G.P.T. three G.P.T. four that th you know the whole sort of lead up to that.", "timestamp": 59.2, "labels": ["environment", "gender", "AI", "safety"], "scores": [0.08015736192464828, 0.07103399187326431, 0.05769447609782219, 0.010616466403007507]}, {"speaker": 2, "text": "So it was easy for me to um to kind of s see where it's going. If you just sort of extrapolate the points on a curve, kind of seeing that trend will continue, then we will have um profound artificial intelligence and obviously at a level that far exceeds uh human intelligence.", "timestamp": 59.2, "labels": ["AI", "environment", "safety", "gender"], "scores": [0.9495446085929871, 0.15663212537765503, 0.0747128576040268, 0.0025485809892416]}, {"speaker": 2, "text": "Um so um but I I'm I'm glad to see at this point that uh people are taking uh safety seriously and I'd I'd uh like to say tha thank you for holding this uh A.I. safety conference. I think actually it will go down in history as being very important.", "timestamp": 59.2, "labels": ["safety", "AI", "environment", "gender"], "scores": [0.9950166940689087, 0.9243884086608887, 0.27547475695610046, 0.02478315867483616]}, {"speaker": 2, "text": "I think it's r it's really qu quite profound um and um and and I do think overall that the potential is there for a artificial intelligence A.I. have most likely a positive effect um and to create a future of abundance where there is no scarcity of goods and services. Um but but it is somewhat the of the the magic genie problem where if you have a magic genie that can grant all the wishes.", "timestamp": 59.2, "labels": ["AI", "environment", "safety", "gender"], "scores": [0.8469934463500977, 0.35891395807266235, 0.04352634772658348, 0.012152560986578465]}, {"speaker": 2, "text": "Um usually those stories um don't end well. Be careful what you wish for, including wishes.", "timestamp": 59.2, "labels": ["environment", "gender", "safety", "AI"], "scores": [0.43326058983802795, 0.10398522764444351, 0.08787181228399277, 0.054148443043231964]}, {"speaker": 1, "text": "you you you talked a little bit about the the summit and thank you for being engaged in it which has been great and people enjoyed having you there participating in this dialogue. Now one of the things that we achieve today in the meetings between the companies and uh the leaders was uh an agreement that externally ideally governments should be doing safety testing of models before they're released.", "timestamp": 178.34, "labels": ["safety", "AI", "environment", "gender"], "scores": [0.9968075752258301, 0.5439673066139221, 0.47675710916519165, 0.015074286609888077]}, {"speaker": 1, "text": "And I think this is something that you've spoken about a little bit. It was something we worked really hard on because you know my job in is to say hang on there is a potential risk here not, a not a definite risk but a potential risk of something that could be bad.", "timestamp": 178.34, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.6915594339370728, 0.580450713634491, 0.3343210518360138, 0.0950256884098053]}, {"speaker": 1, "text": "You know my job is to protect the country and we can only do that if we develop the capability we need in our safety institute and then go in and make sure we can test the models before they are released Delighted. that that happened today.", "timestamp": 178.34, "labels": ["safety", "AI", "environment", "gender"], "scores": [0.9797444343566895, 0.036024369299411774, 0.020142674446105957, 0.006113033276051283]}, {"speaker": 1, "text": "But you know what what's your view on what we should be doing, right You've? talked about the potential risk, right?", "timestamp": 178.34, "labels": ["environment", "AI", "safety", "gender"], "scores": [0.443865031003952, 0.1767612248659134, 0.08025756478309631, 0.039292510598897934]}, {"speaker": 1, "text": "Again we don't know. But you know what are the types of things governments like ours should be doing to manage and mitigate against these risks.", "timestamp": 178.34, "labels": ["environment", "safety", "AI", "gender"], "scores": [0.40314391255378723, 0.39906513690948486, 0.04248166084289551, 0.015164226293563843]}, {"speaker": 2, "text": "Well I I generally think that that it is good for government to play a role when the public safety is is at risk. So um you know f really for the vast majority of software um the public safety is not at risk.", "timestamp": 238.9, "labels": ["safety", "AI", "environment", "gender"], "scores": [0.8687371015548706, 0.06881207227706909, 0.0669618621468544, 0.009729965589940548]}, {"speaker": 2, "text": "I mean if if the if the uh app crashes on your phone or a laptop it's not a c a massive catastrophe. Um but when you talking about digital super-intelligence I think w which does pose a a risk to the public then there is a role for government to play to safeguard the interests of the public.", "timestamp": 238.9, "labels": ["AI", "safety", "environment", "gender"], "scores": [0.735978364944458, 0.47170567512512207, 0.01994497701525688, 0.00962474849075079]}, {"speaker": 2, "text": "And and this is of course true in in many fields um you know aviation, cars uh you know I I I d I deal with regulators uh throughout the world uh because of um s installing being communications, rockets being aerospace and cars you know being trac vehicle transport. So I'm very familiar with dealing with with regulators um and I actually agree with the vast majority of regulations.", "timestamp": 238.9, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.2067161351442337, 0.0017002573003992438, 0.000745900091715157, 0.0004159907693974674]}, {"speaker": 2, "text": "There's a few that I disagree with from time to time but point one percent probably have or le less than one percent of regulations I disagree with. So and there is some concern from uh people in Silicon Valley who who've never ha dealt with regulators before and they think that this is gonna just crush innovation and and slow them down and be annoying.", "timestamp": 238.9, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.35706254839897156, 0.3444576859474182, 0.08702898770570755, 0.0533292330801487]}, {"speaker": 2, "text": "But and and and uh it will be annoying it's, true Um. they're not wrong about that. Um but but I think there's we've learnt over the years that uh having a referee is a good thing.", "timestamp": 238.9, "labels": ["environment", "safety", "gender", "AI"], "scores": [0.5688015222549438, 0.16282053291797638, 0.06089001148939133, 0.04712729901075363]}, {"speaker": 2, "text": "And if you look at any sports game there's always a a referee. And and nobody's suggesting I think to have a sports game without one.", "timestamp": 238.9, "labels": ["safety", "environment", "gender", "AI"], "scores": [0.2306942343711853, 0.08482705056667328, 0.010545126162469387, 0.004899348597973585]}, {"speaker": 2, "text": "Um and and I think that's the the right way to think about this is for um for government to be a a referee to make sure the sportsmen like conduct and and and that the public safety is um you know i i i is addressed that we care about the public safety. Because I th I think there might be t at times too much optimism about technology.", "timestamp": 238.9, "labels": ["safety", "AI", "environment", "gender"], "scores": [0.9883159399032593, 0.05968932807445526, 0.0280868262052536, 0.009088513441383839]}, {"speaker": 2, "text": "And I speak I say that as a technologist I mean so I ought to know. And and uh and and like I said a on on balance I think that that the A.I. will be a a forceful good most likely.", "timestamp": 238.9, "labels": ["AI", "safety", "environment", "gender"], "scores": [0.977617084980011, 0.41683053970336914, 0.27091464400291443, 0.009996301494538784]}, {"speaker": 2, "text": "But the probability of it going bad is not zero percent. So we we just need to mitigate the downside potential.", "timestamp": 238.9, "labels": ["environment", "AI", "safety", "gender"], "scores": [0.6489400267601013, 0.47447341680526733, 0.3832498788833618, 0.0939912348985672]}, {"speaker": 1, "text": "And then how uh you talk about referee and that's what we're trying to create Yeah. well there we go.", "timestamp": 374.14, "labels": ["AI", "environment", "safety", "gender"], "scores": [0.0019044806249439716, 0.0012312257895246148, 0.0011263168416917324, 0.0007516092737205327]}, {"speaker": 1, "text": "I mean you know and we talk about this and Demas and I discussed this a long time ago. And actually you know Demas to his credit and the credit of people in the industry did say that to us.", "timestamp": 374.14, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.6481967568397522, 0.513621985912323, 0.31434375047683716, 0.08510315418243408]}, {"speaker": 1, "text": "I think you know Demas says it's not right that Demas and his colleagues are marking their own homework right, There. needs to be someone independent and that's why we've developed a safety institute here.", "timestamp": 374.14, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.9726608991622925, 0.3817475438117981, 0.1092965379357338, 0.03497590497136116]}, {"speaker": 1, "text": "I mean do you think governments can develop the expertise One? of the things we need to do is they hang on you, know, Demas and Sam all the others have got a lot of very smart people doing this.", "timestamp": 374.14, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.4808763265609741, 0.3778820335865021, 0.1850687861442566, 0.014926029369235039]}, {"speaker": 1, "text": "Governments need to quickly tool up capability-wise, personnel-wise, so which is what we're doing. I I mean do you think it is possible for governments to do that fast enough given how quickly the technology is developing?", "timestamp": 374.14, "labels": ["safety", "environment", "AI", "gender"], "scores": [0.3897460699081421, 0.3349035084247589, 0.33132824301719666, 0.004949953407049179]}, {"speaker": 1, "text": "Or what do we need to do to make sure we do do it quick enough?", "timestamp": 374.14, "labels": ["environment", "safety", "AI", "gender"], "scores": [0.6285971403121948, 0.6155201196670532, 0.22174333035945892, 0.044212982058525085]}, {"speaker": 2, "text": "Mm-hmm. be growing in capability by at at least five fold perhaps ten fold per year.", "timestamp": 432.2, "labels": ["environment", "AI", "safety", "gender"], "scores": [0.47843387722969055, 0.3871578276157379, 0.17717811465263367, 0.03234052285552025]}, {"speaker": 2, "text": "It it'll certainly grow by an order of magnitude next year. So um", "timestamp": 432.2, "labels": ["environment", "AI", "safety", "gender"], "scores": [0.6458895802497864, 0.30962032079696655, 0.11534689366817474, 0.0938018262386322]}]